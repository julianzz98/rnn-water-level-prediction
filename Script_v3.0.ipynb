{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import der Bibliotheken, Definition der Messstellen und Download & Einlesen der Rohdaten\n",
    "\n",
    "Die Messstelle des Pegelstandes, der vorhergesagt werden soll, und die Messstellen, die für die Vorhersage verwendet werden sollen, werden am Anfang des Codes definiert.\n",
    "So kann das Skript leicht auch auf andere Ort angewendet werden. Die Klartextnamen der Messstellen stehen ebenfalls in den Download-Dateien.\n",
    "\n",
    "Neben den im Seminar verwendeten Bibliotheken werden die Bibliotheken \"urllib\" für den Dowload von Dateien, \"zipfile\" für das Entpacken der Dowload-Dateien sowie \"pyarrow\" für ein effizienteres Einlesen von CSV-Dateien (https://pythonspeed.com/articles/pandas-read-csv-fast/) verwendet.\n",
    "\n",
    "Autoren:\n",
    "* Frederic Herrscher\n",
    "* Julian Zilz (@julianzz98)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import der benötigten Bibliotheken\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "from datetime import datetime\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_percentage_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense\n",
    "from zipfile import ZipFile\n",
    "import os\n",
    "import urllib.request \n",
    "import pyarrow\n",
    "\n",
    "# Pegelstand, der vorhergesagt werden soll\n",
    "ms_prediction = '2747900000200'\n",
    "# Messstellen, die für die Vorhersage verwendet werden sollen\n",
    "ms_nieder = ['50040031','50040021','51050021','52080222'] # Niederschlagswerte\n",
    "ms_temp = ['2741500000100','2747390000100','2747900000200'] # Temperaturswerte\n",
    "ms_pegel = ['2741500000100','2743000000100','2747390000100','2747900000200','2741490000200','2746310000100','2746790000100','2744910000100','2742510000100','2742990000200','2741870000100'] # Pegelstände\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download-Ordner für die Dateien wird erstellt\n",
    "dir = \"./data/\"\n",
    "if not os.path.exists(dir):\n",
    "    os.makedirs(dir)\n",
    "\n",
    "# Die Dateien werden heruntergeladen und mithilfe der Bibliothek zipfile entpackt\n",
    "# https://docs.python.org/3/library/urllib.request.html\n",
    "# https://keras.io/examples/timeseries/timeseries_weather_forecasting/\n",
    "uri_nieder = \"https://www.opengeodata.nrw.de/produkte/umwelt_klima/wasser/oberflaechengewaesser/hygon/OpenHygon-Niederschlag-Bestand_CSV.zip\"\n",
    "urllib.request.urlretrieve(uri_nieder,dir + \"Niederschlag.zip\")\n",
    "zip_file_nieder = ZipFile(dir + \"Niederschlag.zip\")\n",
    "zip_file_nieder.extractall(dir)\n",
    "txt_path_nieder = dir + \"nieder_messwerte.txt\"\n",
    "\n",
    "uri_temp = \"https://www.opengeodata.nrw.de/produkte/umwelt_klima/wasser/oberflaechengewaesser/hygon/OpenHygon-Wassertemperatur-Bestand_CSV.zip\"\n",
    "urllib.request.urlretrieve(uri_temp,dir + \"Wassertemperatur.zip\")\n",
    "zip_file_temp = ZipFile(dir + \"Wassertemperatur.zip\")\n",
    "zip_file_temp.extractall(dir)\n",
    "txt_path_temp = dir + \"temp_messwerte.txt\"\n",
    "\n",
    "uri_pegel = \"https://www.opengeodata.nrw.de/produkte/umwelt_klima/wasser/oberflaechengewaesser/hygon/OpenHygon-Pegel-Bestand_CSV.zip\"\n",
    "urllib.request.urlretrieve(uri_pegel,dir + \"Pegelstaende.zip\")\n",
    "zip_file_pegel = ZipFile(dir + \"Pegelstaende.zip\")\n",
    "zip_file_pegel.extractall(dir)\n",
    "txt_path_pegel = dir + \"pegel_messwerte.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DateParser, der nur gültige Datumsangaben importiert. So wird sichergestellt, dass der Type des Feldes immer 'datetime' ist\n",
    "# https://pandas.pydata.org/docs/reference/api/pandas.to_datetime.html\n",
    "def parse_date(x):\n",
    "    try:\n",
    "        return pd.to_datetime(x)\n",
    "    except:\n",
    "        return pd.NaT\n",
    "\n",
    "# Import der benötigten CSV-Dateien\n",
    "niederschlag_messwerte = pd.read_csv(txt_path_nieder, sep=';', parse_dates=['time'], date_parser=parse_date, header = 0, encoding= 'unicode_escape',engine=\"pyarrow\")\n",
    "#niederschlag_messwerte.info()\n",
    "temperatur_messwerte = pd.read_csv(txt_path_temp, sep=';', parse_dates=['time'], date_parser=parse_date, header = 0, encoding= 'unicode_escape',engine=\"pyarrow\")\n",
    "#temperatur_messwerte.info()\n",
    "pegelstand_messwerte = pd.read_csv(txt_path_pegel, sep=';', parse_dates=['time'], date_parser=parse_date, header = 0, encoding= 'unicode_escape',engine=\"pyarrow\", index_col=['time'])\n",
    "#pegelstand_messwerte.info()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data-Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Die Umbenennung der Messwert-Felder hilft beim späteren Prozess\n",
    "pegelstand_messwerte = pegelstand_messwerte.rename(columns={'value(cm)': 'Pegelstand'})\n",
    "temperatur_messwerte = temperatur_messwerte.rename(columns={'value(cm)': 'Temperatur'})\n",
    "niederschlag_messwerte = niederschlag_messwerte.rename(columns={'value(mm/h)': 'Niederschlag'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Für den späteren Join ist es erforderlich, dass alle Felder den gleichen Typ haben\n",
    "pegelstand_messwerte.station_no = pegelstand_messwerte.station_no.astype('string')\n",
    "niederschlag_messwerte.station_no = niederschlag_messwerte.station_no.astype('string')\n",
    "temperatur_messwerte.station_no = temperatur_messwerte.station_no.astype('string')\n",
    "# pegelstand_messwerte.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Die Pegelstände werden von 15 Min. Daten auf 1h zusammengefasst (Resampling)\n",
    "# https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.resample.html\n",
    "\n",
    "pegelstand_messwerte_hour = pegelstand_messwerte.groupby('station_no').resample('1H').mean()\n",
    "pegelstand_messwerte_hour = pegelstand_messwerte_hour.reset_index()\n",
    "pegelstand_messwerte_hour.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Es wird eine leere Tabelle erstellt, die jedes Datum der Pegelstände nur einmal enthält. So können die anderen Daten nun darauf gejoined werden\n",
    "# https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.drop_duplicates.html\n",
    "\n",
    "wertetabelle = pegelstand_messwerte_hour\n",
    "wertetabelle = wertetabelle['time'].drop_duplicates(keep='first')\n",
    "wertetabelle = wertetabelle.to_frame() # wird als Series erstellt, muss daher umgewandelt werden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nun werden die DataFrames auf die einzelnen Messstellen aus der Liste am Anfang gefiltert und mit dem neu erstellten DataFrame gejoined.\n",
    "# https://www.youtube.com/watch?v=_gaAoJBMJ_Q&t=465s\n",
    "# Da wir keine andere Möglichkeit gefunden haben, die Daten wie benötigt aufbereiten zu können, musste dieser Weg gegangen werden\n",
    "\n",
    "for messstelle in ms_temp: # Es wird der eingangs definierte Array mit den Messstellen geloopt\n",
    "    join_df = temperatur_messwerte.query('station_no == @messstelle') # Der Datensatz wird auf die Messstelle gefiltert\n",
    "    wertetabelle = pd.merge(wertetabelle,join_df[['time','Temperatur']],on='time', how='left') # Nun werden die Daten gejoined\n",
    "    wertetabelle = wertetabelle.rename(columns={'Temperatur': f'Temperatur_{messstelle}'}) # Die Umbenennung ist erforderlich, da sich sonst Spaltennamen wiederholen\n",
    "\n",
    "for messstelle in ms_pegel:\n",
    "    join_df = pegelstand_messwerte_hour.query('station_no == @messstelle')\n",
    "    wertetabelle = pd.merge(wertetabelle,join_df[['time','Pegelstand']],on='time', how='left')\n",
    "    wertetabelle = wertetabelle.rename(columns={'Pegelstand': f'Pegelstand_{messstelle}'})\n",
    "\n",
    "for messstelle in ms_nieder:\n",
    "    join_df = niederschlag_messwerte.query('station_no == @messstelle')\n",
    "    wertetabelle = pd.merge(wertetabelle,join_df[['time','Niederschlag']],on='time', how='left')\n",
    "    wertetabelle = wertetabelle.rename(columns={'Niederschlag': f'Niederschlag_{messstelle}'})\n",
    "\n",
    "wertetabelle = wertetabelle.set_index('time')\n",
    "\n",
    "# Der letzte Messzeitpunkt ist oft sehr unvollständig, daher löschen wir ihn (Die Daten werden von einigen Messstellen verspätet bereitgestellt)\n",
    "wertetabelle = wertetabelle.drop(wertetabelle.index[-1])\n",
    "wertetabelle.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nun werden die NaN-Werte entfernt. Wir nutzen dafür eine Interpolation\n",
    "# https://www.youtube.com/watch?v=EaGbS7eWSs0\n",
    "\n",
    "wertetabelle = wertetabelle.replace('', np.nan).astype(float)\n",
    "wertetabelle = wertetabelle.interpolate()\n",
    "\n",
    "# Wenn der erste Wert der Tabelle NaN ist, wird er nicht durch die Interpolate-Methode ersetzt. Daher ersetzen wir ihn durch den nächsten Wert\n",
    "wertetabelle = wertetabelle.bfill()\n",
    "wertetabelle.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hier wird nun der Pegelstand, den wir vorhersagen, an die erste Stelle gepackt. Das benötigen wir später beim Split in X und Y Data\n",
    "# https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.reindex.html\n",
    "\n",
    "wertetabelle = wertetabelle.reindex(columns=[f'Pegelstand_{ms_prediction}'] + list(wertetabelle.columns.drop(f'Pegelstand_{ms_prediction}')))\n",
    "# wertetabelle.to_csv('wertetabelle_after_prep.csv')\n",
    "# wertetabelle.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaling, Erstellung von Sequenzen und der Trainings- und Testdaten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scaling der Daten mit StandardScaler (https://machinelearningmastery.com/standardscaler-and-minmaxscaler-transforms-in-python/)\n",
    "scaler = StandardScaler()\n",
    "scaler = scaler.fit(wertetabelle)\n",
    "scaled_df = scaler.transform(wertetabelle)\n",
    "# np.savetxt('scaled_data.csv', scaled_df, delimiter=',')\n",
    "scaled_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "Y = []\n",
    "predictX = []\n",
    "\n",
    "n_future = 24 # Anzahl der Stunden, die wir in die Zukunft prognostizieren möchten\n",
    "n_past = 96 # Anzahl der vergangenen Stunden, die wir verwenden möchten, um die Zukunft vorherzusagen\n",
    "\n",
    "# Erstellung der Sequenzen von X und Y Daten\n",
    "for i in range (n_past, len(scaled_df) - n_future + 1):\n",
    "    X.append(scaled_df[i - n_past : i])\n",
    "    Y.append(scaled_df[i : i+n_future, 0])\n",
    "\n",
    "for i in range (n_past, len(scaled_df) + 1):\n",
    "    predictX.append(scaled_df[i - n_past : i])\n",
    "\n",
    "X, Y, predictX = np.array(X), np.array(Y), np.array(predictX)\n",
    "print(X.shape)\n",
    "print(Y.shape)\n",
    "print(predictX.shape)\n",
    "# np.savetxt(\"Y.csv\", Y, delimiter=\",\")\n",
    "\n",
    "# Erstellung der Trainings- und Testdaten\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html\n",
    "trainX, testX, trainY, testY = train_test_split(X,Y,test_size=0.2, shuffle=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Erstellen, Kompilieren und Trainieren des RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Erstellen des Modells mit LSTM und Dense-Layern\n",
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=(trainX.shape[1], trainX.shape[2]), return_sequences=True))\n",
    "\n",
    "model.add(LSTM(64, return_sequences=True, dropout=0.1))\n",
    "\n",
    "model.add(LSTM(64, return_sequences=False, dropout=0.1))\n",
    "\n",
    "model.add(Dense(trainY.shape[1]))\n",
    "\n",
    "opt = keras.optimizers.Adam() # Festelegen des Optimizers\n",
    "model.compile(optimizer = opt, loss=\"mse\") # Kompilieren des Models\n",
    "model.summary()\n",
    "\n",
    "# Trainieren des Modells\n",
    "history = model.fit(trainX, trainY, epochs=27, batch_size=8, validation_data=(testX,testY))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Erstellen einer Vorhersage & Invertieren des Scalings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Erstellen einer Vorhersage mithilfe des trainierten Modells\n",
    "forecast = model.predict(predictX)\n",
    "forecast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Invertierung des Skalierung. Da die Skalierung für jede Spalte der Inputdaten unterschiedlich ist, wird eine Hilfstabelle benötigt, um die korrekten Werte zu erhalten\n",
    "\n",
    "invert_dataframe = pd.concat([wertetabelle.iloc[n_past-1:,0] for i in range(n_future)], axis=1)\n",
    "\n",
    "invert_scaler = StandardScaler()\n",
    "invert_scaler = invert_scaler.fit(invert_dataframe)\n",
    "invert_scaled_dataframe = invert_scaler.transform(invert_dataframe)\n",
    "#print(invert_scaled_dataframe)\n",
    "print(invert_scaled_dataframe.shape)\n",
    "\n",
    "y_pred = invert_scaler.inverse_transform(forecast)\n",
    "y_pred\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation der vorhergesagten Daten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Für die Evaluation werden die vorhergesagten Daten mit den realen Daten verglichen\n",
    "# Für den Vergleich wird jeweils der erste und letzte Vorhersagewert verwendet\n",
    "\n",
    "real = wertetabelle.iloc[n_past:, 0].copy().reset_index()\n",
    "\n",
    "pred_first = pd.DataFrame(y_pred[:,0], columns=[\"Vorhersage (first step)\"]).reset_index(drop=True)\n",
    "\n",
    "pred_last = pd.DataFrame(y_pred[:,n_future-1], columns=[\"Vorhersage (last step)\"]).reset_index(drop=True)\n",
    "pred_last.set_index(pd.Index(range(n_future-1,len(pred_first)+n_future-1)), inplace=True) # Index muss angepasst werden\n",
    "pred_last"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Es wird eine Ergebnistabelle erstellt\n",
    "results = pd.merge(real, pred_first, how=\"outer\", left_index=True, right_index=True)\n",
    "results = pd.merge(results, pred_last, how=\"outer\", left_index=True, right_index=True)\n",
    "\n",
    "results = results.rename(columns={f'Pegelstand_{ms_prediction}': 'Realer Messwert'})\n",
    "\n",
    "# Da keine Zeitwerte für die Zukunftswerte vorhanden sind, müssen diese mit der Pandas-Funtion TimeDelta hinzugefügt werden\n",
    "# https://www.tutorialspoint.com/python_pandas/python_pandas_timedelta.htm\n",
    "for i in range(0,n_future):\n",
    "    results[\"time\"] = results[\"time\"].fillna(results[\"time\"].shift() + pd.Timedelta(hours=1))\n",
    "results = results.set_index(\"time\")                      \n",
    "# results.to_csv('results.csv')\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Berechnen der Genauigkeit des ersten und letzten Zeitschrittes der Vorhersage mithilfe des Mean Squerad Errors und des Mean Absolute Percentage Errors\n",
    "\n",
    "accuracy = results.iloc[n_future:-n_future].copy()\n",
    "\n",
    "mape_first_step = mean_absolute_percentage_error(accuracy[\"Realer Messwert\"], accuracy[\"Vorhersage (first step)\"])\n",
    "print(f\"Der MAPE des first-step beträgt {mape_first_step}\")\n",
    "\n",
    "mape_last_step = mean_absolute_percentage_error(accuracy[\"Realer Messwert\"], accuracy[\"Vorhersage (last step)\"])\n",
    "print(f\"Der MAPE des last-step beträgt {mape_last_step}\")\n",
    "\n",
    "mse_first_step = mean_squared_error(accuracy[\"Realer Messwert\"], accuracy[\"Vorhersage (first step)\"])\n",
    "print(f\"Der MSE des first-step beträgt {mse_first_step}\")\n",
    "\n",
    "mse_last_step = mean_squared_error(accuracy[\"Realer Messwert\"], accuracy[\"Vorhersage (last step)\"])\n",
    "print(f\"Der MSE des last-step beträgt {mse_last_step}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Erstellung der Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Konfiguration des ersten Plots (Genauigekeit der Vorhersagen)\n",
    "# https://www.activestate.com/resources/quick-reads/how-to-display-a-plot-in-python/\n",
    "\n",
    "# Einstellen einer Farbpalette\n",
    "# https://towardsdatascience.com/how-to-use-your-own-color-palettes-with-seaborn-a45bf5175146\n",
    "colors = [\"#001A61\", \"#E0572E\", \"#019417\"]\n",
    "sns.set_palette(sns.color_palette(colors))\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(22, 6))\n",
    "ax.plot(results)\n",
    "ax.legend(results.columns)\n",
    "\n",
    "# Setze Achsenbeschriftungen und den Titel\n",
    "ax.set_xlabel(\"Datum\")\n",
    "ax.set_ylabel(\"Pegelstand (cm)\")\n",
    "ax.set_title(\"Vergleich der realen Pegelstände mit den vorhergesagten Werten\",fontsize=15, pad=25)\n",
    "ax.tick_params(axis=\"both\", direction=\"out\", length=5, width=2, colors=\"black\")\n",
    "ax.legend(results.columns,loc=\"upper left\", fontsize=10)\n",
    "\n",
    "# Wochentage auf der X-Achse anzeigen\n",
    "# https://matplotlib.org/stable/api/dates_api.html#matplotlib.dates.WeekdayLocator\n",
    "ax.xaxis.set_major_formatter(mdates.DateFormatter('%d.%m.%Y'))\n",
    "ax.xaxis.set_major_locator(mdates.WeekdayLocator(byweekday=1, interval=1))\n",
    "\n",
    "ax.xaxis.set_tick_params(rotation=45, labelsize=10)\n",
    "plt.xticks(rotation=0, size=8)\n",
    "plt.grid(linestyle=':', linewidth='0.5')\n",
    "plt.margins(x=0)\n",
    "\n",
    "plt.savefig('result_plot.svg', format='svg')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Für den zweiten Plot (Vorhersage der nächsten n Zeitschritte) müssen die Tabellen zusammengefügt werden, um sie in einem Diagramm anzeigen zu können.\n",
    "pred_future = y_pred[-1:]\n",
    "pred_future = np.reshape(pred_future, (pred_future.shape[1], ))\n",
    "pred_future = pd.DataFrame(pred_future, columns=[\"Vorhergesagter Messwert\"])\n",
    "pred_future.set_index(pd.Index(range(len(pred_first)-1,len(pred_first)+n_future-1)), inplace=True)\n",
    "# print(pred_future)\n",
    "\n",
    "results_future = pd.merge(real, pred_future, how=\"outer\", left_index=True, right_index=True)\n",
    "results_future = results_future.rename(columns={f'Pegelstand_{ms_prediction}': 'Realer Messwert'})\n",
    "\n",
    "for i in range(0,n_future):\n",
    "    results_future[\"time\"] = results_future[\"time\"].fillna(results_future[\"time\"].shift() + pd.Timedelta(hours=1))\n",
    "results_future = results_future.set_index(\"time\")\n",
    "results_future.loc[results_future.index[-n_future-1], 'Vorhergesagter Messwert'] = results_future.loc[results_future.index[-n_future-1], 'Realer Messwert']                  \n",
    "results_future"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Konfiguration des zweiten Plots\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6, 6))\n",
    "ax.plot(results_future.tail(60))\n",
    "ax.legend(results_future.columns)\n",
    "\n",
    "# Setze die Achsenbeschriftungen und den Titel\n",
    "ax.set_xlabel(\"Datum\")\n",
    "ax.set_ylabel(\"Pegelstand (cm)\")\n",
    "ax.set_title(\"Vorhersage der kommenden 24 Stunden\",fontsize=15, pad=25)\n",
    "ax.tick_params(axis=\"both\", direction=\"out\", length=5, width=2, colors=\"black\")\n",
    "ax.legend(results_future.columns,loc=\"upper left\", fontsize=10)\n",
    "\n",
    "# https://matplotlib.org/stable/api/dates_api.html#matplotlib.dates.WeekdayLocator\n",
    "ax.xaxis.set_major_formatter(mdates.DateFormatter('%d.%m.%Y'))\n",
    "ax.xaxis.set_major_locator(mdates.DayLocator())\n",
    "ax.xaxis.set_minor_locator(mdates.HourLocator())\n",
    "\n",
    "ax.xaxis.set_tick_params(rotation=45, labelsize=10)\n",
    "plt.xticks(rotation=0, size=8)\n",
    "plt.grid(linestyle=':', linewidth='0.5')\n",
    "plt.margins(x=0)\n",
    "\n",
    "plt.savefig('result_plot_zoom.svg', format='svg')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optionaler Plot: Loss-Funktion verschiedener RNN-Konfigurationen\n",
    "\n",
    "Um die Loss-Funktion verschiedener RNN-Konfigurationen zu vergleichen, müssen weitere Modelle kompiliert und trainiert werden. Wir haben den folgenden Code auskommentiert, um die Laufzeit des Skriptes zu verkürzen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = Sequential()\n",
    "# model.add(LSTM(64, input_shape=(trainX.shape[1], trainX.shape[2]), return_sequences=True))\n",
    "\n",
    "# model.add(LSTM(32, return_sequences=True, dropout=0.1))\n",
    "\n",
    "# model.add(LSTM(32, return_sequences=False, dropout=0.1))\n",
    "\n",
    "# model.add(Dense(trainY.shape[1]))\n",
    "\n",
    "# opt = keras.optimizers.Adam()\n",
    "# model.compile(optimizer = opt, loss=\"mse\")\n",
    "# model.summary()\n",
    "\n",
    "# history2 = model.fit(trainX, trainY, epochs=27, batch_size=8, validation_data=(testX,testY))\n",
    "\n",
    "# model = Sequential()\n",
    "# model.add(LSTM(32, input_shape=(trainX.shape[1], trainX.shape[2]), return_sequences=True))\n",
    "\n",
    "# model.add(LSTM(16, return_sequences=True, dropout=0.1))\n",
    "\n",
    "# model.add(LSTM(8, return_sequences=False, dropout=0.1))\n",
    "\n",
    "# model.add(Dense(trainY.shape[1]))\n",
    "\n",
    "# opt = keras.optimizers.Adam()\n",
    "# model.compile(optimizer = opt, loss=\"mse\")\n",
    "# model.summary()\n",
    "\n",
    "# history3 = model.fit(trainX, trainY, epochs=27, batch_size=8, validation_data=(testX,testY))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Erstellen des Plots der Loss-Funktionen \n",
    "\n",
    "# his1 = history.history\n",
    "# his2 = history2.history\n",
    "# his3 = history3.history\n",
    "\n",
    "# train_loss1 = his1['loss']\n",
    "# train_loss2 = his2['loss']\n",
    "# train_loss3 = his3['loss']\n",
    "\n",
    "# # X-Achse (Epochen)\n",
    "# epochs = range(1, len(train_loss1) + 1)\n",
    "\n",
    "# # Plotten des Trainings- und Validierungs-Losses beider Models\n",
    "# plt.plot(epochs, train_loss1, label='Loss des Models mit 128/64/64 Neuronen')\n",
    "# plt.plot(epochs, train_loss2, label='Loss des Models mit 64/32/32 Neuronen')\n",
    "# plt.plot(epochs, train_loss3, label='Loss des Models mit 32/16/8 Neuronen')\n",
    "\n",
    "# # Beschriftungen und Legende\n",
    "# plt.title('Loss-Funktionen unterschiedlicher Modell-Konfigurationen', pad=15)\n",
    "# plt.xlabel('Epochen')\n",
    "# plt.ylabel('Loss')\n",
    "# plt.legend()\n",
    "# plt.grid(linestyle=':', linewidth='0.5')\n",
    "# plt.margins(x=0)\n",
    "\n",
    "# plt.savefig('loss_function_plot.svg', format='svg')\n",
    "# plt.show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
